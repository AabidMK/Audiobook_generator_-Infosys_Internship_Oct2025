A Practical Review of Machine Learning Models for Malware Detection Using EMBER 2018-v2

By
GOWSHIK J
SANJAY S


Abstract
With the increasing volume of executable file analysis in cybersecurity, the risk of malware infections has grown, leading to significant financial and operational damage for individuals and organizations. Current research focuses on the application of machine learning for the detection and classification of these malware programs. Accordingly, the present work uses static metadata features from executable files to detect and classify malware using the XGBoost and Random Forest algorithms. The highest results were obtained with the XGBoost algorithm, achieving 96.1 % precision and 96.2 % accuracy, recall, and F1-score, demonstrating the effectiveness of both machine learning and static malware analysis in mitigating security threats in endpoint environments.
KEYWORDS: machine learning / malware / algorithms / matrices
1. Introduction
Cyberattacks have grown rapidly in recent years, with malware being one of the most common and damaging threats. Malware — short for malicious software — is designed to disrupt, damage, or gain unauthorized access to computer systems. It often hides inside seemingly harmless programs and spreads through downloads, software updates, or repackaged applications.
As internet usage and software distribution have increased, so has the risk of malware infections. These attacks can compromise user privacy, disrupt system performance, and cause significant financial losses.
To address this, researchers have turned to machine learning (ML) as a way to detect malware more effectively. Instead of relying on traditional signature-based detection, ML models can learn patterns from large datasets and identify suspicious behavior based on features extracted from executable files.
In our study, we focus on static malware analysis using the EMBER 2018 dataset, which contains metadata from Windows PE (Portable Executable) files. We apply a feature selection technique to reduce dimensionality and improve model performance. Then, we train and compare two popular ML algorithms — Random Forest and XGBoost — to classify files as either benign or malicious.
Our goal is to evaluate which model performs better in terms of accuracy, precision, recall, and F1-score, and to build a simple, interpretable prediction pipeline that can be deployed in real-world scenarios.

2. Dataset Overview
The EMBER 2018 dataset is a benchmark dataset for static malware analysis. It contains metadata features extracted from PE files, including byte histograms, imported functions, section sizes, and entropy measures. For this study, we used a balanced subset of the dataset, consisting of both benign and malicious samples.
Each sample includes 2381 engineered features, labeled as F1 through F2381. These features were selected to capture meaningful patterns in executable structure and behavior. To reduce dimensionality and improve model performance, we applied a variance threshold filter, removing features with low variability across samples. The resulting feature selector was saved and reused during prediction to ensure consistency.


3. Model Training and Evaluation
Random Forest
Random Forest is an ensemble learning method that builds multiple decision trees and aggregates their predictions. It is known for its robustness and interpretability. In our experiments, RF was trained with 100 estimators and a fixed random seed for reproducibility.
XGBoost
XGBoost is a gradient boosting framework that builds trees sequentially, optimizing for errors at each step. It tends to perform well on structured data and is often used in competitive machine learning tasks. We configured XGBoost with a learning rate of 0.1 and a maximum depth of 6.
Both models were trained on the same feature-selected input and evaluated using a held-out test set.
4. Results and Comparison
The performance of both models was measured using standard classification metrics. XGBoost consistently outperformed Random Forest across all metrics:
Confusion Matrix Analysis

Confusion Matrix Analysis



Graphs:

RANDOM FOREST(FEATURE VS IMPORTANT SCORES)





XG-BOOST (FEATURE VS IMPORTANT SCORE)


Random Forest:
True Positives (TP): 475
True Negatives (TN): 470
False Positives (FP): 30
False Negatives (FN): 25
XGBoost:
True Positives (TP): 485
True Negatives (TN): 480
False Positives (FP): 20
False Negatives (FN): 15
XGBoost showed better precision and recall, with fewer misclassifications overall. Random Forest was slightly more prone to false positives, but still performed reliably.
5. File Upload and Prediction Workflow
To make the models usable outside of the training environment, we built a simple prediction pipeline. The process involves:
Creating a dummy input file: A .parquet file with 2381 features (F1 to F2381) is generated to match the expected format.
Uploading the file: The user uploads the file into the prediction notebook.
Running the prediction: The model and feature selector are loaded, the input is transformed, and the prediction is returned as either "Malware" or "Benign".


One challenge was ensuring that the input file matched the training format exactly — including feature names and column order. This was resolved by reordering the input columns using the selector’s feature_names_in_ attribute before transformation.







6.Result 
The line graph clearly shows that XGBoost outperforms Random Forest in accuracy, achieving 96.2% compared to 94.0%. This visual comparison highlights XGBoost’s stronger classification performance on the EMBER 2018 dataset.





7. Conclusion
Both Random Forest and XGBoost proved effective for malware classification using the EMBER 2018 dataset. XGBoost delivered higher accuracy and fewer misclassifications, making it the preferred choice for deployment. However, Random Forest offered faster training and simpler interpretation, which may be beneficial in resource-constrained environments.
The project also highlighted the importance of consistent preprocessing and careful file handling during deployment. By building a reusable prediction pipeline, we demonstrated how machine learning models can be integrated into real-world malware detection workflows.
